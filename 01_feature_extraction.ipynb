{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_base_path = './'\n",
    "\n",
    "fake_dataset_dir = f\"{relative_base_path}dataset/manipulated_sequences\"\n",
    "real_dataset_dir = f\"{relative_base_path}dataset/original_sequences\"\n",
    "\n",
    "fake_output_dir = f\"{relative_base_path}out/0/\"\n",
    "real_output_dir = f\"{relative_base_path}out/1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10981,
     "status": "ok",
     "timestamp": 1735395270035,
     "user": {
      "displayName": "Faraz Khalil",
      "userId": "15571848968372978323"
     },
     "user_tz": 0
    },
    "id": "aTQQcaPUGJqS",
    "outputId": "358f5169-68d0-4fdc-ccf6-fb3640a5cd3b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from models.blink_detection.DetectBlinking import DetectBlinking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def faces_count(path):\n",
    "    try:\n",
    "        cap = cv.VideoCapture(path)\n",
    "        if not cap.isOpened():\n",
    "            raise IOError(f\"Failed to open video: {path}\")\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            annotated_image = frame.copy()\n",
    "            mp_face_detection = mp.solutions.face_detection\n",
    "            face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5)\n",
    "            result = face_detection.process(cv.cvtColor(annotated_image, cv.COLOR_BGR2RGB))\n",
    "\n",
    "            return len(result.detections)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1735395277456,
     "user": {
      "displayName": "Faraz Khalil",
      "userId": "15571848968372978323"
     },
     "user_tz": 0
    },
    "id": "Wyuyb2jUHYPN"
   },
   "outputs": [],
   "source": [
    "def get_and_save_features(p, path, output_filename, idx):\n",
    "    detected_faces = faces_count(p)\n",
    "    if detected_faces != 1: return\n",
    "    else:\n",
    "        blink_counter = DetectBlinking(p, 0.3, 4, return_features=True)\n",
    "        video_features = blink_counter.process_video()\n",
    "        video_features = np.array(video_features)\n",
    "        print(f\"{idx} Video Processed | Features: \", video_features.shape, len(video_features))\n",
    "\n",
    "        if not(os.path.exists(f\"{path}{output_filename}\")):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "            ds = {\"ORE_MAX_GIORNATA\": 5}\n",
    "            np.save(os.path.join(path, output_filename), ds)\n",
    "\n",
    "        np.save(f\"{path}/{output_filename}\", video_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1735395464855,
     "user": {
      "displayName": "Faraz Khalil",
      "userId": "15571848968372978323"
     },
     "user_tz": 0
    },
    "id": "trgdPoukHcRw"
   },
   "outputs": [],
   "source": [
    "def get_features_and_save_npy(video_paths, output_dir, output_files):\n",
    "    for idx, p in enumerate(video_paths):\n",
    "        _, tail = os.path.split(p)\n",
    "        name = tail.split(\".\")[0]\n",
    "\n",
    "        np_path = output_dir + f\"{name}.npy\"\n",
    "        output_filename = f\"{name}.npy\"\n",
    "        path = output_dir\n",
    "\n",
    "        if np_path in output_files:\n",
    "            print(f\"{idx} => File missed: \", np_path)\n",
    "        else:\n",
    "            get_and_save_features(p, path, output_filename, idx)\n",
    "            print(f\"{idx} => File processed: \", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 856,
     "status": "ok",
     "timestamp": 1735395466427,
     "user": {
      "displayName": "Faraz Khalil",
      "userId": "15571848968372978323"
     },
     "user_tz": 0
    },
    "id": "OWqKZL9u46HM",
    "outputId": "8a6eee42-3e25-49ef-8cd0-8c1bfe68240f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_fake_paths_npy:  (3174,)\n",
      "extracted_real_paths_npy:  (1157,)\n",
      "fake_mp4_paths:  8067\n",
      "real_mp4_paths:  1363\n"
     ]
    }
   ],
   "source": [
    "extracted_fake_paths_npy = np.array(glob.glob(fake_output_dir + \"*.npy\"))\n",
    "extracted_real_paths_npy = np.array(glob.glob(real_output_dir + \"*.npy\"))\n",
    "\n",
    "print(\"extracted_fake_paths_npy: \", extracted_fake_paths_npy.shape)\n",
    "print(\"extracted_real_paths_npy: \", extracted_real_paths_npy.shape)\n",
    "\n",
    "fake_mp4_paths = glob.glob(fake_dataset_dir + \"/*/*/*/*.mp4\")\n",
    "real_mp4_paths = glob.glob(real_dataset_dir + \"/*/*/*/*.mp4\")\n",
    "print(\"fake_mp4_paths: \", len(fake_mp4_paths))\n",
    "print(\"real_mp4_paths: \", len(real_mp4_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and save them as .npy files\n",
    "get_features_and_save_npy(fake_mp4_paths, fake_output_dir, extracted_fake_paths_npy)\n",
    "get_features_and_save_npy(real_mp4_paths, real_output_dir, extracted_real_paths_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MpwFkCE0h2XL"
   },
   "outputs": [],
   "source": [
    "def pad_to_max_length(array, max_length, pad_value = 0):\n",
    "    if array.ndim == 2:\n",
    "        padded = np.pad(array, ((0, max_length - len(array)), (0, 0)), mode=\"constant\", constant_values=pad_value)\n",
    "    else:\n",
    "        padded = np.pad(array, (0, max_length - len(array)), mode='constant', constant_values=pad_value)\n",
    "\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_fake_paths_npy:  3174 (3174,)\n",
      "extracted_real_paths_npy:  1157 (1157,)\n"
     ]
    }
   ],
   "source": [
    "extracted_fake_paths_npy = np.array(glob.glob(fake_output_dir + \"*.npy\"))\n",
    "extracted_real_paths_npy = np.array(glob.glob(real_output_dir + \"*.npy\"))\n",
    "\n",
    "print(\"extracted_fake_paths_npy: \", len(extracted_fake_paths_npy), extracted_fake_paths_npy.shape)\n",
    "print(\"extracted_real_paths_npy: \", len(extracted_real_paths_npy), extracted_real_paths_npy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_features:  3174\n",
      "real_features:  1157\n"
     ]
    }
   ],
   "source": [
    "# Load the features and pad them to the same length\n",
    "fake_features = []\n",
    "real_features = []\n",
    "\n",
    "# Load the features, \n",
    "for idx, path in enumerate(extracted_fake_paths_npy):\n",
    "    features = np.load(path)\n",
    "    fake_features.append(features)\n",
    "\n",
    "for idx, path in enumerate(extracted_real_paths_npy):\n",
    "    features = np.load(path)\n",
    "    real_features.append(features)\n",
    "\n",
    "# fake_features = np.array(fake_features)\n",
    "# real_features = np.array(real_features)\n",
    "\n",
    "print(\"fake_features: \", len(fake_features))\n",
    "print(\"real_features: \", len(real_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of features:  1814\n"
     ]
    }
   ],
   "source": [
    "# Get the max length of the features\n",
    "max_length = max(max(len(features) for features in fake_features), max(len(features) for features in real_features))\n",
    "print(\"Max length of features: \", max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fake_features_padded:  (2622, 1814, 3)\n",
      "real_features_padded:  (1126, 1814, 3)\n"
     ]
    }
   ],
   "source": [
    "# Pad the features\n",
    "fake_features_padded = []\n",
    "real_features_padded = []\n",
    "\n",
    "\n",
    "for idx, features in enumerate(fake_features):\n",
    "    if len(features) > 200:\n",
    "        padded_arr = pad_to_max_length(features, max_length)\n",
    "        fake_features_padded.append(padded_arr)\n",
    "\n",
    "fake_features_padded = np.array(fake_features_padded)\n",
    "\n",
    "for idx, features in enumerate(real_features):\n",
    "    if len(features) > 200:\n",
    "        padded_arr = pad_to_max_length(features, max_length)\n",
    "        real_features_padded.append(padded_arr)\n",
    "\n",
    "real_features_padded = np.array(real_features_padded)\n",
    "\n",
    "print(\"fake_features_padded: \", fake_features_padded.shape)\n",
    "print(\"real_features_padded: \", real_features_padded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_dataset:  (3748, 1814, 3)\n",
      "Y_dataset:  (3748,)\n"
     ]
    }
   ],
   "source": [
    "# Save the fake and real features in a single .npy file with the respective targets i.e. 0 for fake and 1 for real\n",
    "fake_targets = np.zeros(fake_features_padded.shape[0])\n",
    "real_targets = np.ones(real_features_padded.shape[0])\n",
    "\n",
    "all_features = np.concatenate((fake_features_padded, real_features_padded), axis=0)\n",
    "all_targets = np.concatenate((fake_targets, real_targets), axis=0)\n",
    "\n",
    "print(\"X_dataset: \", all_features.shape)\n",
    "print(\"Y_dataset: \", all_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed(f\"{relative_base_path}out/only_esn_features\", X_dataset=all_features, Y_dataset=all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
